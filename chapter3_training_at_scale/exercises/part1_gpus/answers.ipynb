{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import benchmark\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import List, Optional, Callable, Tuple, Dict, Literal, Set \n",
    "# Make sure exercises are in the path\n",
    "orig_dir = os.getcwd()\n",
    "chapter = r\"chapter3_training_at_scale\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = exercises_dir / \"part7_toy_models_of_superposition\"\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "import part1_gpus.tests as tests\n",
    "\n",
    "# Add root dir, so we can import from chapter 0 material\n",
    "root_dir = exercises_dir.parent.parent.resolve()\n",
    "if str(root_dir) not in sys.path: sys.path.append(str(root_dir))\n",
    "os.chdir(root_dir)\n",
    "from chapter0_fundamentals.exercises.part3_resnets.solutions import ResNet34\n",
    "os.chdir(orig_dir)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference         7.91%       1.898ms       100.00%      24.007ms      24.007ms             1  \n",
      "                     aten::conv2d         0.25%      59.000us        67.68%      16.248ms     812.400us            20  \n",
      "                aten::convolution         0.69%     166.000us        67.43%      16.189ms     809.450us            20  \n",
      "               aten::_convolution         0.53%     127.000us        66.74%      16.023ms     801.150us            20  \n",
      "         aten::mkldnn_convolution        65.72%      15.777ms        66.21%      15.896ms     794.800us            20  \n",
      "                 aten::batch_norm         0.20%      47.000us        14.53%       3.488ms     174.400us            20  \n",
      "     aten::_batch_norm_impl_index         0.39%      94.000us        14.33%       3.441ms     172.050us            20  \n",
      "          aten::native_batch_norm        13.57%       3.258ms        13.93%       3.345ms     167.250us            20  \n",
      "                 aten::max_pool2d         0.02%       4.000us         5.52%       1.324ms       1.324ms             1  \n",
      "    aten::max_pool2d_with_indices         5.50%       1.320ms         5.50%       1.320ms       1.320ms             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.007ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-06-19 10:09:11 3166:3166 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-06-19 10:09:11 3166:3166 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-06-19 10:09:11 3166:3166 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "inputs = torch.randn(5, 3, 224, 224)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPU table ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        22.67%       1.203ms        99.87%       5.299ms       5.299ms       0.000us         0.00%       1.583ms       1.583ms             1  \n",
      "                                      aten::convolution         2.75%     146.000us        35.71%       1.895ms      94.750us       0.000us         0.00%       1.050ms      52.500us            20  \n",
      "                                     aten::_convolution         1.66%      88.000us        32.96%       1.749ms      87.450us       0.000us         0.00%       1.050ms      52.500us            20  \n",
      "                                aten::cudnn_convolution        18.00%     955.000us        31.30%       1.661ms      83.050us       1.050ms        66.33%       1.050ms      52.500us            20  \n",
      "                                           aten::conv2d         1.62%      86.000us        36.54%       1.939ms      96.950us       0.000us         0.00%       1.034ms      51.700us            20  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     284.000us        17.94%     284.000us       8.875us            32  \n",
      "                           aten::_batch_norm_impl_index         0.98%      52.000us        22.03%       1.169ms      58.450us       0.000us         0.00%     277.000us      13.850us            20  \n",
      "                                 aten::cudnn_batch_norm        11.14%     591.000us        21.05%       1.117ms      55.850us     277.000us        17.50%     277.000us      13.850us            20  \n",
      "                                       aten::batch_norm         1.68%      89.000us        22.67%       1.203ms      60.150us       0.000us         0.00%     270.000us      13.500us            20  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     161.000us        10.17%     161.000us      53.667us             3  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.306ms\n",
      "Self CUDA time total: 1.583ms\n",
      "\n",
      "--- CPU table ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-06-19 10:13:13 3166:3166 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        23.06%       1.098ms        99.85%       4.755ms       4.755ms       0.000us         0.00%       1.580ms       1.580ms             1  \n",
      "                                           aten::conv2d         2.10%     100.000us        39.04%       1.859ms      92.950us       0.000us         0.00%       1.013ms      50.650us            20  \n",
      "                                      aten::convolution         0.90%      43.000us        38.22%       1.820ms      91.000us       0.000us         0.00%       1.046ms      52.300us            20  \n",
      "                                     aten::_convolution         1.78%      85.000us        37.32%       1.777ms      88.850us       0.000us         0.00%       1.046ms      52.300us            20  \n",
      "                                aten::cudnn_convolution        21.57%       1.027ms        35.53%       1.692ms      84.600us       1.046ms        66.20%       1.046ms      52.300us            20  \n",
      "                                       aten::batch_norm         1.13%      54.000us        22.60%       1.076ms      53.800us       0.000us         0.00%     277.000us      13.850us            20  \n",
      "                           aten::_batch_norm_impl_index         1.05%      50.000us        21.46%       1.022ms      51.100us       0.000us         0.00%     277.000us      13.850us            20  \n",
      "                                 aten::cudnn_batch_norm         9.89%     471.000us        20.41%     972.000us      48.600us     277.000us        17.53%     277.000us      13.850us            20  \n",
      "                                       cudaLaunchKernel        18.35%     874.000us        18.35%     874.000us       6.992us       0.000us         0.00%       0.000us       0.000us           125  \n",
      "                                            aten::empty         6.91%     329.000us         6.91%     329.000us       3.257us       0.000us         0.00%       0.000us       0.000us           101  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.762ms\n",
      "Self CUDA time total: 1.580ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "print('--- Without inference mode (compute gradients) ---')\n",
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1').cuda()\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "# CPU\n",
    "print('--- With inference mode (don\\'t compute gradients) ---')\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1').cuda()\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        with torch.inference_mode():\n",
    "            model(inputs)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
